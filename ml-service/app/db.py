import os
import time
import psycopg2
from psycopg2.extras import execute_values
import pandas as pd
import json
from sqlalchemy import create_engine

def get_connection():
    """–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ PostgreSQL –∑ –ø–æ–≤—Ç–æ—Ä–Ω–∏–º–∏ —Å–ø—Ä–æ–±–∞–º–∏."""
    while True:
        try:
            conn = psycopg2.connect(
                host=os.getenv("DB_HOST", "db"),
                port=os.getenv("DB_PORT", "5432"),
                database=os.getenv("DB_NAME", "fakenewsdb"),
                user=os.getenv("DB_USER", "postgres"),
                password=os.getenv("DB_PASSWORD", "100317"),
            )
            print("‚úÖ –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î —É—Å–ø—ñ—à–Ω–µ!")
            return conn
        except psycopg2.OperationalError as e:
            print("‚ùå –ë–î —â–µ –Ω–µ –≥–æ—Ç–æ–≤–∞, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 2 —Å–µ–∫...", e)
            time.sleep(2)


def save_news_and_labels(news_df, label_df):
    """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è NewsItem + Label."""
    conn = get_connection()
    with conn.cursor() as cur:
        ids = []

        # üîπ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ NewsItem
        for _, row in news_df.iterrows():
            published_at = row["published_at"]
            if pd.isna(published_at):
                published_at = None  # PostgreSQL NULL
            cur.execute(
                """
                INSERT INTO NewsItem (title, text, source, published_at, url, lang)
                VALUES (%s, %s, %s, %s, %s, %s)
                RETURNING id
                """,
                (
                    row["title"],
                    row["text"],
                    row["source"],
                    published_at,
                    row["url"],
                    row["lang"],
                ),
            )
            ids.append(cur.fetchone()[0])

        # üîπ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ Label
        for i, row in enumerate(label_df.itertuples()):
            timestamp = row.timestamp
            if pd.isna(timestamp):
                timestamp = None
            cur.execute(
                """
                INSERT INTO Label (news_id, label, annotator, confidence, timestamp, predicted_label)
                VALUES (%s, %s, %s, %s, %s, %s)
                """,
                (
                    ids[i],
                    row.label,
                    row.annotator,
                    row.confidence,
                    timestamp,
                    None  # —Å–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–≥–Ω–æ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π
                ),
            )

        conn.commit()
        print(f"üíæ {len(ids)} –Ω–æ–≤–∏–Ω —Ç–∞ –º—ñ—Ç–æ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ.")
    conn.close()


def save_embeddings_bulk(news_ids, embeddings, model_id="sentence-bert"):
    
    conn = get_connection()
    with conn.cursor() as cur:
        for i, emb in enumerate(embeddings):
            cur.execute(
                """
                INSERT INTO Embedding (news_id, model_id, dim, vector_ref)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (news_id) DO UPDATE
                SET dim = EXCLUDED.dim, vector_ref = EXCLUDED.vector_ref;
                """,
                (news_ids[i], model_id, len(emb), emb.tolist())
            )
        conn.commit()
    conn.close()


def save_predicted_label(news_id, predicted_label, confidence):
    conn = get_connection()
    with conn.cursor() as cur:
        cur.execute(
            """
            UPDATE Label
            SET predicted_label = %s,
                confidence = %s
            WHERE news_id = %s
            """,
            (predicted_label, float(confidence), news_id)
        )
        conn.commit()
    conn.close()
    print(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è news_id={news_id}: {predicted_label} (confidence={confidence})")


def save_explanation(news_id, method, payload, fidelity=None):
    conn = get_connection()
    with conn.cursor() as cur:
        cur.execute(
            """
            INSERT INTO Explanation (news_id, method, payload, fidelity)
            VALUES (%s, %s, %s, %s)
            RETURNING id
            """,
            (news_id, method, json.dumps(payload), fidelity)
        )
        exp_id = cur.fetchone()[0]
        conn.commit()
    conn.close()
    print(f"üíæ Explanation {method} –¥–ª—è news_id={news_id} –∑–±–µ—Ä–µ–∂–µ–Ω–æ (id={exp_id}).")
    return exp_id


def save_projection_points(news_ids, method, coords, meta=None):
    """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–æ—á–æ–∫ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó (UMAP/t-SNE)."""
    conn = get_connection()
    with conn.cursor() as cur:
        for i, nid in enumerate(news_ids):
            cur.execute(
                """
                INSERT INTO ProjectionPoint (news_id, method, x, y, meta)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (news_id, method) DO UPDATE
                SET x = EXCLUDED.x, y = EXCLUDED.y, meta = EXCLUDED.meta;
                """,
                (
                    nid,
                    method,
                    float(coords[i][0]),
                    float(coords[i][1]),
                    json.dumps(meta) if meta else None,
                ),
            )
        conn.commit()
    conn.close()
    print(f"üíæ ProjectionPoints ({method}) –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {len(news_ids)} –∑–∞–ø–∏—Å—ñ–≤.")

def load_training_data():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–∞–Ω—ñ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è (id, text, label), –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω—ñ –∑–∞ ID."""
    engine = create_engine("postgresql+psycopg2://postgres:100317@db/fakenewsdb")
    query = """
        SELECT n.id, n.text, l.label
        FROM NewsItem n
        JOIN Label l ON n.id = l.news_id
        WHERE l.predicted_label IS NULL
        ORDER BY n.id;
    """
    df = pd.read_sql(query, engine)
    return df
